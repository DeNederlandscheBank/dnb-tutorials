{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data'\n",
    "FILENAME_TAXO = 'simple_taxo.csv'\n",
    "FILENAME_RULES = '2020-01-09 Set aanvullende controleregels Solvency II_tcm46-386880.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read simplified taxonomy of Solvency 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxo = pd.read_csv(os.path.join(DATA_PATH, FILENAME_TAXO), encoding='latin-1')\n",
    "df_taxo = df_taxo.drop(\"Unnamed: 0\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_taxo.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct test Solvency 2 instance (put here your own data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxo_datatypes = dict()\n",
    "for row in df_taxo.index:\n",
    "    taxo_datatypes[df_taxo.loc[row, \"datapoint\"]] = df_taxo.loc[row, \"dtype\"]\n",
    "    \n",
    "unique_dp = list(df_taxo['datapoint'].unique())\n",
    "data_dp = [[0 if taxo_datatypes[i]=='int64' else 0.0 if taxo_datatypes[i]=='float64' else \"text\" for i in unique_dp]]\n",
    "\n",
    "df = pd.DataFrame(columns = unique_dp, data = data_dp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read DNBs Additional Validation Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vr = pd.read_excel(os.path.join(DATA_PATH, FILENAME_RULES), header = 1)\n",
    "df_vr = df_vr.set_index('ControleRegelCode')\n",
    "df_vr = df_vr.drop('S.28.01_129', axis = 0)\n",
    "df_vr.fillna(\"\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vr['Formule']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_brackets(s):\n",
    "    \"\"\"Add brackets around expressions with & and | (this is not consistent in EVA2)\n",
    "    TODO: should not apply is AND or OR is in string text\n",
    "    \"\"\"\n",
    "    item = re.search(r'(.*)\\s*([&|\\||>|<|!=|<=|>=|==])\\s*(.*)', s)\n",
    "    if item is not None:\n",
    "        if item[2].strip() in ['&', '|']:\n",
    "            return '('+ add_brackets(item[1]) + ') ' + item[2].strip() + ' (' + add_brackets(item[3]) + ')'\n",
    "        else:\n",
    "            return add_brackets(item[1]) + item[2].strip() + add_brackets(item[3])\n",
    "    else:\n",
    "        return s.strip()\n",
    "    \n",
    "def preprocess(s):\n",
    "    \"\"\"Transform EVA2 code to Python Pandas code\"\"\"\n",
    "    res = s\n",
    "    res = res.replace(\"=\" , \"==\")\n",
    "    res = res.replace(\">==\" , \">=\")\n",
    "    res = res.replace(\"<==\" , \"<=\")\n",
    "    res = res.replace(\"<>\", \"!=\")\n",
    "    res = res.replace(\"< >\", \"!=\") # the space between < and > should be deleted in EVA2\n",
    "    res = res.replace('\"', \"'\")\n",
    "    res = res.replace(' OR{', \" | {\")\n",
    "    res = res.replace(' OR ', \" | \")\n",
    "    res = res.replace(' AND ', \" & \")\n",
    "    res = res.replace(\" )\", \")\")\n",
    "    res = res.replace(';', \",\") # this should be corrected in EVA2\n",
    "    return res\n",
    "\n",
    "def transform_datapoints(s, columns):\n",
    "    \"\"\"Transform EVA2 datapoints to Python Pandas datapoints\"\"\"\n",
    "    res = s\n",
    "    not_found = []\n",
    "    for item in re.findall(r'{(.*?)}', res):\n",
    "        res = res.replace(\"{\"+item+\"}\", \"df['\"+item+\"']\")\n",
    "        if item not in list(columns):\n",
    "            not_found.append(item)\n",
    "    return res, not_found\n",
    "\n",
    "def transform_conditional_expression(g):\n",
    "    \"\"\"Transform EVA2 conditional expression to Python Pandas code\"\"\"\n",
    "    item = re.search(r'IF\\s*(.*)\\s*THEN\\s*(.*)\\s*', g)\n",
    "    if item is not None:\n",
    "        co_str = 'df[('+add_brackets(item[1])+') & ('+add_brackets(item[2])+\")]\"\n",
    "        ex_str = 'df[('+add_brackets(item[1])+') & ~('+add_brackets(item[2])+\")]\"\n",
    "    else:\n",
    "        co_str = 'df[('+add_brackets(g)+')]'\n",
    "        ex_str = 'df[~('+add_brackets(g)+')]'\n",
    "    return co_str, ex_str\n",
    "\n",
    "def evaluate_strings(co_str, ex_str):\n",
    "    \"\"\"Evaluate Python Pandas string for confirmation and exceptions\"\"\"\n",
    "    try:\n",
    "        co = len(eval(co_str, {'df': df, 'MAX': np.maximum, 'MIN': np.minimum, 'SUM': np.sum}))\n",
    "        ex = len(eval(ex_str, {'df': df, 'MAX': np.maximum, 'MIN': np.minimum, 'SUM': np.sum}))\n",
    "        return \"Correctly parsed (#co=\" + str(co)+\", #ex=\"+str(ex)+\")\"\n",
    "    except:\n",
    "        return \"Parse error: \" + co_str\n",
    "        \n",
    "def get_all_datapoints(template, dim):\n",
    "    \"\"\"Get all rows or columns in the taxonomy given a template with column or row\"\"\"\n",
    "    d = dim.lower()\n",
    "    if 'r' in d:\n",
    "        l = list(df_taxo[(df_taxo['template']==template) & (df_taxo['row']==dim)]['column'].values)\n",
    "        if l != ['']:\n",
    "            dp = [template + \",\" + d + \",\" + column for column in l]\n",
    "        else:\n",
    "            dp = [template + \",\" + d]\n",
    "        return dp\n",
    "    elif 'c' in d:\n",
    "        l = list(df_taxo[(df_taxo['template']==template) & (df_taxo['column']==dim)]['row'].values)\n",
    "        if l != ['']:\n",
    "            dp = [template + \",\" + row + \",\" + d for row in l]\n",
    "        else:\n",
    "            dp = [template + \",\" + d]\n",
    "        return dp        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_rules(df_data, df_rules, df_taxo):\n",
    "    for row in df_rules.index:\n",
    "        print(\"Rule \" + row + \": \", end='')\n",
    "        original = df_rules.loc[row, 'Formule']\n",
    "        g = preprocess(original)\n",
    "        g, not_found = transform_datapoints(g, df_data.columns)\n",
    "        if not_found == []:\n",
    "            # Simple expression with complete datapoints\n",
    "            co_str, ex_str = transform_conditional_expression(g)\n",
    "            print(evaluate_strings(co_str, ex_str))\n",
    "        else:\n",
    "            # Datapoints in expression should be expanded with the content of Rijen and Kolommen\n",
    "#             to_select_rows = df_rules.loc[row, \"Rijen\"].replace(\"(\", \"\").replace(\")\", \"\")\n",
    "#             to_select_columns = df_rules.loc[row, \"Kolommen\"].replace(\"(\", \"\").replace(\")\", \"\")\n",
    "#             if (to_select_rows != \"\") and not('all' in to_select_rows.lower()):\n",
    "#                 to_select_rows = [\"r\" + r if len(r)==4 else r for r in to_select_rows.split(\";\")]\n",
    "# #               print(to_select_rows)\n",
    "#             if (to_select_columns != \"\") and not('all' in to_select_columns.lower()): \n",
    "#                 to_select_columns = [\"c\" + r if len(r)==4 else r for r in to_select_columns.split(\";\")]\n",
    "# #               print(to_select_columns)\n",
    "            expansion = []\n",
    "            for datapoint in not_found:\n",
    "                template = datapoint[0:13]\n",
    "                dim = datapoint[14:]\n",
    "                l = get_all_datapoints(template, dim)\n",
    "            print(\"Complex expression, not yet implemented\")\n",
    "#                 if l is None:\n",
    "#                     print(\"Datapoint string: \" + str(datapoint))\n",
    "#                 else:\n",
    "#                     if len(l) == 0:\n",
    "#                         print(\"Datapoint not found \" + str(datapoint))\n",
    "#                     else:\n",
    "#                         expansion.append(l)\n",
    "#             if expansion !=[]:\n",
    "#                 print(\"Not yet implemented: expand possible \")\n",
    "#                 for row in to_select_rows:\n",
    "#                     a = datapoint[0:13] + \",\" + row + datapoint[13:19]\n",
    "#                     if a in df_taxo['datapoint'].values:\n",
    "#                         print(a + \": found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_rules(df, df_vr, df_taxo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['S.15.01.04.01,c0070']>0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
